Hello. In the previous video, we had seen the dining philosophers’ problem. And we had seen for the initial naive solutions that we had for the problem, it could result in something known as deadlocks. So, in this video, we will look at more in detail about deadlocks, and how they are handled in the system.

So let us say we have two processes A and B, and we have two resources R 1 and R 2. So, these resources could be anything in the system which have a limited quantity. For example, the resources could be as something as small as a file stored in the disc or it could be a printer which is used to print or a plotter, a scanner and so on. So, essentially the arrow from R 1 to A indicates that A is currently holding the resource. For instance, if R 1 is the file; that means, A has currently open the file exclusively and is doing some operations onto the file. In a similar way, the resource R 2 is held by B. So if it is a printer, for instance, if R 2 is a printer, it means that B is currently using the printer to print some particular document.

Now, consider this particular scenario where the process A holds the resource R 1, and process B holds the resource R 2; but at the same time, process A is requesting to use R 2. So, essentially the process A is waiting for R 2 to be obtained; and process B is waiting for the resource R 1 to be obtained. So, to take an example, process A is opened the file and is using a particular file which is stored in the disk. And at the same time, for instance, it wants to print the file to the resource R 2 which we assumed was a printer. Now in a similar way, process B is currently holding this resource that is using this particular resource and it wants to open and utilize this particular resource R 1.

So, what we see that over here, we have a scenario called a Deadlock. Essentially, a deadlock is a state in the system where each process in the deadlock is waiting for an event that an other process in that set can cause. For instance, over here, the process A is waiting for the resource R 2 which is held by B; B in turn is waiting for R 1 which is held by A. We have a set of two processes A and B; and each process in the set is waiting for the other process to do something and each process in the set is waiting for the other process to do a particular thing. For example, A is waiting for B to release this particular resource R 2, while B is also waiting for A to release the resource R 1.

So, deadlock like this is a very critical situation that would occur in systems. And when this deadlocks occur, it could lead to process A and B in this case waiting for an infinite time continuously waiting without doing any useful work. So, such deadlocks should be analyzed thoroughly. So, in this particular video, we will see how such deadlocks are handled in systems. Now, in order to study deadlocks, we use graphs like this, these are known as Resource Allocation Graphs. Now resource allocation graphs or directed graphs used to model the various resource allocations in the system. And there by determine whether a deadlock has occurred or a deadlock is potentially going to occur and so on. So, in this directed graph, we represent resources by a square. So, instance R 1 and R 2 are resources and they are represented by the square as shown over. In a similar way, circles as shown over here are used to represent processes. And as we have seen before, arrows from the process to the resource that is directed from the process to the resource would indicate that a request is made for that resource. For example, over here the arrow from A to R 1 indicates that A is requesting for resource R 1; similarly B, in this case is requesting for resource R 2. So, these requests are made to the operating system and if possible the operating system will then allocate that resource to the corresponding process.

So, when that happens the graph will look like this, essentially the direction of the arrow has changed. Now the arrow moves from R 1 to A, indicating that A holds resource R 1. Similarly, the arrow from R 2 to B indicates that B holds resource R 2. There are four conditions in order that a deadlock occurs.

So, we will now look at each of these conditions for a deadlock. So, the first is Mutual Exclusion. So, what we mean by this is that each resource in the system is either available or currently assigned to exactly one process. So, for instance over here we have resource R 1 which is free. So, it is not assigned to any particular process, so this is fine. While this is also fine where the resource is allocated to exactly one process, but in order that deadlocks happen this kind of scenario should not be present that is the resource cannot be shared between two processes A and B.

The next condition for a deadlock is Hold and wait that is a process holding a resource can request another resource that is for example, in this case the resource R 1 is held by process A and while having R 1, A is also requesting for another resource R 2, so it essentially holding R 1 and waiting for R 2.

The third condition for a deadlock to happen is No preemption. Essentially, it should not be the case that resources which an operating system previously granted for a particular process is forcibly taken away from that process. That is the OS or another entity in the system cannot forcibly remove a resource which has been allocated to a particular process. Instead processes should explicitly release the resource by themselves that is whenever the process wants it should release the resource by itself.

So, a fourth requirement is the Circular wait. What this means is that there is a circular chain of two or more processes, each of which is waiting for a resource held by the next member of the chain. So, we see over here with that we have a circular chain and there is a wait over here because process A is waiting for process B to release resource R 2; and process B is in turn waiting for process A to release the resource R 1. So, we have a circular wait condition over here. So, these 4 conditions: mutual exclusion, hold and wait, no preemption and circular wait must be present in the system in order that a deadlock could occur.

So, if for instance, we were able to build a system where one of these conditions, were not present. For example, suppose we build a system where processes cannot hold a particular resource and wait for another resource at the same time. So, such system would never have any deadlocks. On the other hand, suppose a system has been developed where all of these things are possible that is there is a mutual exclusion when using resources, a process could hold a resource and wait for another one, once allocated they cannot be forcefully preempted from the resource and circular wait mechanisms are allowed then deadlocks could potentially occur. So, having all these conditions does not imply that a deadlock has occurred. It only implies that there is a probability of deadlock occurring in the future.

So, this being said “a deadlock in a system is a chanced event”. Essentially, it depends on several factors such as the way resources are requested by processes, the way allocations are made for these resources, the way de-allocations are made by the operating system and so on. So, only if certain order of these requests an allocation happen and only then will a deadlock occur. So, a small variation in the request and allocations may cause the deadlock to not occur.

So let us see some examples of this. So let us say we have three processes in the system A, B and C, and there are three resources as well R, S and T. So, each process could request and release resources at sometime during its execution. So obviously, a release can be made by a process only after the request is made. So, these request and release of resources are given to the operating system at various time instance, depending on how A, B and C get scheduled and how they are executed.

So let us consider this particular sequence that A requests R, and then B requests S, C request T. Then A requests S, B requests T, and C requests R. So, this is one potential order for how request occur. So, we can use our resource graphs or resource allocation graphs to view this. So, we see that A requests R and the operating system will then allocate the resource R to A, then corresponding to B requests S, the allocation will be of S will be to B. Then C requests T and the OS will allocate T to C. Then A requests S, so there is a line like this. B requests T there is a line over here and C requests R. So, we have the four conditions that we have seen in the previous slide, have all been met. For instance, the circular wait you see is achieved here. R is held by A, while A requests S; S is held by B and at the same time B request T. Now T is held by C, while simultaneously C is requesting for R. So, you see that each process is waiting for an other process in this set to release a particular resource. So, we have a deadlocked scenario over here.

Now, we will see that if the same requests and allocations are done in a slightly different manner then the deadlock will not occur. For example, R is allocated to A, and then T gets allocated to C; then A requests S and gets allocated to A. Then C requests R, so we have this over here. Now, A releases R, so there is no more line over here or an edge over here then A releases S, and therefore R can be allocated to C. So, you see that depending on the requests and releases, we are able to achieve a situation where each and every request or release can be serviced by the operating system. So, in such a scenario, we have not obtained the deadlock.

Now, we have seen that deadlock is indeed a probabilistic event and could occur with some probability. Now one way to reduce the probability is by having multiple resources present in the system. So, we had seen that this was a deadlock state, essentially because A is waiting for resource R 2 to be released by B, and B in turn is waiting for resource R 1. Now one way this can be solved is by having multiple resources, while this particular solution will not always work, and essentially depends on the type of resources, it may help to some extent.

For instance, if we have two resources of exactly the same type then both A’s request as well as B’s request could be managed that is the resource if we have two types of R 1 or in other words if you have a duplicate of the resource R 1 then that can be given to A as well as B. Similarly, a duplicate of the resource R 2 can be given to A and B simultaneously. So, what this means is that for example, we could have two printers present and A can be allocated one printer while B could be allocated the other printer while this does not completely eradicate deadlocks, it may reduce the likelihood the deadlocks may occur.

Now, the next question is in a system which could have deadlocks, should deadlocks be handled? So, this is a debatable question, essentially is not an easy thing to answer, because the cost of having a prevention mechanisms or to detect deadlocks is extremely high, and it will cost huge overheads in the operating system.

So, the other aspect was known as the ostrich algorithm is to completely ignore that deadlocks could occur and run the system without any prevention or any deadlock detection mechanisms. So, either choice that is either having some deadlock prevention or detection mechanisms or just ignoring the entire aspects of deadlock would need to be made during the OS design time or rather the system design time. So, various things need to be discussed before a decision can be made, such as what is the probability that a deadlock occurs? Is it likely that a deadlock will occur every week, or every month or once in 5 years or so on? Second what is the consequence of a deadlock? Essentially, how critical a deadlock could be? For instance, if a deadlock occurs on my desktop, I could simply reboot the system and it’s not going to affect me much. On the other hand if a deadlock occurs, say in a safety critical application like a spacecraft or a rocket kind of scenario, then the consequence could be disastrous. Therefore, we need to argue about these two aspects, essentially if the probability that a deadlock occurs is very frequent then probably the OS would require some measures in order to handle the deadlock.

On the other hand, if the deadlock occurs very sporadic may be on average once in five years or so then you may not require to have or handle a deadlock in the operating system. So now let us assume that we need some mechanism in our operating system to handle deadlocks. So, what can we do about this?

Essentially, there are three ways that deadlocks can be handled. One is by Detection and recovery, second by Avoidance and third by Prevention. So let us look at the first case, that is detection and recovery and first how are deadlocks detected?

Essentially for the operating system to detect deadlocks, it requires to know the current resource allocation in the system. Essentially which process holds which resources and it also requires to know the current request allocation by the processes. Essentially which process is waiting for which resources, and the OS will then use this information to detect if the system is in a deadlocked state. So, the way the detection could work is by finding cycles in the resource allocation graphs. For instance, if this is the resource allocation graph for the various resources in the system, the OS will detect a cycle present.

For example, over here, we have a cycle between the processes D, E and G then the OS will say that these three processes are indeed in the deadlock state. Now the other aspect is there could be request as shown over here, where there is resource S and it is requested simultaneously by A, D, F and C. So, we see that this is not in a deadlock state because there is some sequence of allocation of S to all these processes. For instance one possible allocation came for S is that first S be allocated to A then A will use the resource S for some time, and then after it complete using S, S can be then allocated to C, and after which S is allocated to F, and then D. So, essentially the allocation of S could be sequential among these four processes. So, this will not have a deadlock.

However, the presence of a cycle in the resource allocation graph will indicate that a deadlock is present in the system. This technique of finding cycles in the resource allocation graph would work well with systems where there were one resource of each type. Now suppose we had systems where there were multiple resources of each type then another algorithm would be required. So let us give an example of how that would work. Let us say in a system we have four resources: tape drives, plotters, scanners and CD ROMs. Further, there are 4 tape drives, 2 plotters, 3 scanners and 1 CD-ROM. Then let us also say that we have three processes executing in the system P 1, P 2, P 3, and this is the current allocation matrix. So, the row 1 is with respect to process P 1. This means that the process P 1 does not have any tape drives, does not have any plotters, is allocated 1 scanner and no CD-ROMs. Similarly, process 2 is allocated 2 tape drives and 1 C D ROM and process 3 is allocated 1 plotter and 2 scanners.

Now, this particular set A determines the resource available; essentially out of the 4 tape drives that we have, if you look into this corresponding column over here in the current allocation matrix we have seen that 2 is used. So, what remain is 4 minus 2 that is 2 tape drives are free and available to be allocated. So, similarly if you look at plotters, out of the 2 plotters 1 is allocated and 1 is free. Out of the 3 scanners, we see that all 3 scanners are allocated, so it is 0 over here. Similarly, there are no CD-ROMs also available to be allocated. Now, in addition to this we have a request matrix, essentially which process is waiting for what, is represented in this matrix. For example, process p 1 requests 2 more tape drives and 1 CD ROM. So, process P 2 requires 1 tape drive and 1 scanner, and process P 3 requires 2 tape drives and 1 plotter. Now the goal of having such definitions or such representations of the resources allocations and requests is to determine if there exists a sequence of allocations of these requests, so that all request can be met. If such a case is possible, then there is no deadlock present. So let us see if we can allocate these requests by the 3 processes.

So let us take a process P 1 and let us see the request by process P 1 can be met. So, it requires 2 tape drives and we see that 2 tape drives are available. So, this is fine and 1 CD-ROM is requested, but there are no CD-ROMs is available. So, process P 1 cannot execute. So, the process P 1 cannot be allocated all its resources. So, it cannot continue to execute. Let us see for about process P 2. So, process P 2 requires 1 tape drive which can be allocated to it because it is available; and it requires 1 scanner, but 0 are available. So, similarly, process P 2 cannot be satisfied as well, and process P 2 will also need to wait. Now let see the third case where for process 3, there are 2 tape drives which can be met, 1 request for a plotter which can be met and 1 request for a scanner which cannot be met.

So, process P 3 also cannot be satisfied its request. So, P 3 also will wait. So, P, 1 P 2 and P 3 are all waiting for the request, and therefore the state is in a deadlock because none of the requests by any of these processes can be met and therefore, all the processes will need to be waiting. If you look at another example where there is a small change. We have just reduced the number of scanners required by process P 3. So, in such a case, we see that both the tape drives requested by process P 3 can be met by the system, the single plotter can be also met and there are no scanners and no CD-ROMs that are required. And therefore, we see that all the request can be allocated to process P 3, therefore P 3 can be satisfied and we do not have a deadlock over here. So, in this way, deadlocks can be detected by the operating system, based on the current allocation matrix and the request matrix.

So, once the deadlocks is detected, what next should the operating system do? So, there could be various things that the OS could do. So, one thing is that it could raise an alarm, that is tell users and administrator that indeed deadlock has been detected.

Then a second way is to force a preemption that is you force a particular resource to be taken away from a process and given to another process. For instance, it could be like R 2 was a printer and it is currently held by B. So, what could be done was that the printer could be forced to be taken away from B, while it is allocated to A for some time and thus the deadlock will be broken, this is as shown over here. So, B no longer has other resource R 2, but R 2 is given to A.

Then a third method is by using a technique known as rollback. So, with rollback, both processes A and B as they execute will be check pointed. So, by check point we mean that the state of the process gets stored on to the disk. The process executes for some time and then the entire state of the process gets stored on to the disk. Now storing the state of the process on the disk, will allow the processes to execute from the point where it has been check pointed, now the checkpoint state. So, as time progresses more check points are taken periodically as shown over here. Now, let us say a deadlock is detected after sometime then what could happen is that the system could rollback to the last non deadlock state that is over here. So, how the rollback occurs would be by loading the state of process A and B in this particular example to the last known state as shown over here.

Now process A and B will continue to execute from this state and the deadlock may not occur again. Essentially we have seen that since deadlock is a probabilistic event by modifying the ordering in which the allocations are made we could prevent this particular deadlock.

A fourth way is to kill processes. Essentially, if process A and B are in a deadlock state, killing one of these processes would break the deadlock. So, typically the lower important or the less priority process would be killed.
