All the ARM Cortex-M processors are based on Thumb-2 technology, which allows a mixture of 16-bit and 32-bit instructions to be used within one operating state.  This is different from classic ARM processors such as the ARM7TDMI.

Early ARM processors (prior to the ARM7TDMI processor) supported a 32-bit instruction set called the ARM instruction set. It evolved for a few years, progressing from ARM architecture version 1 to version 4. It is a powerful instruction set, which supports conditional execution of most instructions and provides good performance. However, it often requires more program memory when compared to 8-bit and 16-bit architecture. As demand for 32-bit processors started to increase in mobile phone  applications, where power and cost are often both critical, a solution was needed to reduce the program size.

In 1995, ARM introduced the ARM7TDMI processor, which supports a new operation state that runs a new 16-bit instruction set (Figure 5.1). This 16-bit instruction set is called “Thumb” (it is a play on words to indicate that it has smaller size than the ARM instruction set). The ARM7TDMI can operate in the ARM state, the default state, and also in the Thumb state. During operation, the processor switches between ARM state and Thumb state under software control. Parts of the application program are compiled with ARM instructions for higher performance, and the remaining parts are compiled as Thumb instructions for better code density. By providing this twostate mechanism, the applications can be squeezed into a smaller program size, while maintaining high performance when needed. In some cases, the Thumb code provides a code size reduction of 30% compared to the equivalent ARM code. The Thumb instruction set provides a subset of the ARM instruction set. In the ARM7TDMI processor design, a mapping function is used to translate Thumb instructions into ARM instructions for decoding so that only one instruction decoder is needed. The two states of operation are still supported in newer ARM processors, such as the Cortex-A processor family and the Cortex-R processor family.

Although the Thumb instruction set can provide most of the same commonly used functionality as the ARM instructions, it does have some limitations, such as restrictions on the register choices for operations, available addressing modes, or a reduced range of immediate values for data or addresses.

In 2003, ARM announced Thumb-2 technology, a method to combine 16-bit and 32-bit instruction sets in one operation state. In Thumb-2, a new superset of the Thumb instructions were introduced, with many as 32-bit size, hence they can handle most of the operations previously only possible in the ARM instruction set. However, they have different instruction encodingto the ARM instruction set. In 2006, ARM released the Cortex-M3 processor, which utilizes Thumb-2
technology and supports just the Thumb operation state. Unlike earlier ARM processors, it does not support the ARM instruction set. Since then, more CortexM processors have been introduced, implementing different ranges of the Thumb instruction set for different markets. Since the Cortex-M processors do not support ARM instructions, they are not backward compatible with classic ARM processors such as the ARM7TDMI. In 2011, ARM announced the ARMv8 architecture, which has a new instruction set for 64-bit operations. Currently the support for the ARMv8 architecture is limited to Cortex-A processors only, and does not cover Cortex-M processors.

( see Figure 5.2 ) The instruction set design of the Cortex-M processors is upward compatible from Cortex-M0, to Cortex-M3, and then to the Cortex-M4. Therefore code compiled for the Cortex-M0/M0þ/M1 processor can run on the Cortex-M3 or Cortex-M4 processors, and code compiled for CortexM3 can also run on the Cortex-M4 processor.

Most of the instructions in ARMv6-M are 16-bit, and some are available in both 16-bit and 32-bit format. When an operation can be carried out in 16-bit, the compiler will normally choose the 16-bit version to give a smaller code size. The 32-bit version might support a greater choice of registers (e.g., high registers), larger immediate data, longer address range, or a larger choice of addressing modes. However, for the same operation, the 16-bit version and the 32-bit version of an instruction will take the same amount of time to execute.

( Figure 5.3 ) For general data processing and I/O control tasks, the Cortex-M0 and the CortexM0þ processors are entirely adequate. If your application needs to process more complex data, perform faster divide operations, or requires the data processing to be done faster, then you might need to upgrade to the Cortex-M3 or Cortex-M4 processor. If you need to have the best performance in DSP applications or floating point operations, then the Cortex-M4 is a better choice.
