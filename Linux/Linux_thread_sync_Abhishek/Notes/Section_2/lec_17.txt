We will going to discuss how threads execute in a concurrent fashion and then in parallel fashion. And after that, how threads execute in a singular fashion on a typical computer system. So in this example, you can see that there are three threads T1, T2 and T3. And let us suppose that the computer system has only one CPU resource, right? Now let us suppose that there is some array which contains 18 elements. 30 is assigned the first six elements of the array. The thread T2 is assigned the next six elements of the array and the thread. T3 is assigned the next six elements of the array.

So now as we know that threads are nothing, but they are workers and workers need to do some work. So let us assign work to each of these threads. So let's say that the thread T1, T2 and T3 has to compute the sum of six elements of the array which is assigned to them. So t1 is supposed to compute the sum of the elements from one and six. The t2 is supposed to compute the sum of the elements of the array from 7 to 12. And similarly, t3 is supposed to compute the sum of the elements of the array from 13 to 18. So note the point here is that that the work allotted to each of these threads are non-overlapping work, No element of the array which belongs to the thread t one will ever be accessed or processed or manipulated by any other thread in the system. So it simply means that each of these threads are assigned tasks which is completely independent on each other. Now let us see that how threads T1, T2 and T3 will going to execute the assigned tasks to them in a concurrent fashion.

So let us suppose that it is the thread t one which gets the CPU by the operating system. So when the thread t one gets the CPU, the thread t one starts running. So it will start computing the sum of the elements of the array which is assigned to it. So now let us suppose that the thread t one computes the sum of the array that is one, two and three, and the moment it computes the sum of the elements of the array till element number three, the operating system chooses to remove the thread t one from the CPU. And load the thread. T2 on the CPU. It simply means that the operating system has chosen to perform context switching from thread t1 to thread. T to be noted that your operating system can perform context switching when the thread has executed on the CPU for a sufficient amount of time. So in this case the execution state of the thread T1 is that that the thread T1 has successfully completed the some of the elements of the array till element number three. This is called storage of the context of the thread t1. Now the same exercise repeats with the thread t2. Now it is the thread t2 which is assigned the CPU and like the thread t1 the thread T2 is also able to compute the sum of the elements of the array which belong to the thread t2. So let us suppose that thread T2 has successfully computed the sum of elements seven, eight and nine. Right and now operating system again chooses to take the CPU away from the thread T2 and assign the CPU again to the thread t3. So now the thread t1 and t2 rest in the scheduling queue of the operating system.

So the operating system maintains some queue which we call it as ready queue or scheduling queue. All the threads which are waiting for the CPU will wait in this queue. You will study this in pretty much more detail when you will study the thread scheduling algorithms. So now going with the thread T3 when the thread T3 has been assigned the CPU, the thread T3 will start doing its job. And let us suppose that when the thread T3 has successfully completed the sum of the elements of the array 13, 14 and 15, then again, the operating system does the same thing. It takes the CPU away from the thread T3 right. So you can see that each of these threads share the CPU one by one and the context switching happens from thread t1 to thread T2 and then from thread t2 to thread T3. So once the thread T3 is placed in the ready queue, the operating system will pick up the first thread from the ready queue and again try to assign a CPU to this thread. So it simply means that thread t1 is assigned the CPU again and now thread t1 will resume the task where it left last time, so it will now resume computing the sum of the elements of the array. And let us suppose that this time the thread T1 completes the summation of all the elements of the array that was assigned to it. now t1 has completed its task, right? And 31 can choose to terminate itself. Similarly, 32 is also assigned the CPU. And let us suppose that 32 also finishes its pending work. That is, it computes the sum of the elements of the array ten, 11 and 12 as well. And the same goes with the thread. 33 right. So all the threads are again assigned the CPU again. So you can see that these threads execute in coordination with each other. And this coordination is completely controlled by the operating system. It is your operating system which decides which thread to preempt of the CPU that is removed from the CPU and which thread to load on the CPU. So this pattern of execution of threads one by one, sharing the CPU as a resource is an example of concurrent execution of the thread. You can see that all these threads shows the property of progression. Each thread was doing its job though partially, but it was doing.

now let us discuss that, how threads execute in the system in a parallel fashion. So the problem statement is still the same, that there are three threads in the system and each thread is assigned some tasks to perform and the task is nothing. But each of these threads have to compute the sum of the elements of their respective arrays. Now, to realize the parallelization between the threads, you need to have more hardware resources in the system. So it is for this reason that instead of one CPU now you have three CPUs. So let us say that this is CPU one, this is CPU two and this is CPU three. We have already seen that the parallel execution demands more resources so that those resources are utilized by their users in parallel. So in this case the resources are CPU and the users of this resource are threads. So when it comes to the parallel execution of the threads, the operating system will schedule the thread one on the CPU one it will schedule the thread two on the CPU two and it will schedule the thread three on the CPU Three. And we have already assumed that each of these threads are assigned non-overlapping work to do right. None of the threads infringes with each other's work. None of the threads produce any kind of obstacle in the work execution of the other threads. So it simply translates to that thread T1 and T2 and threat T3 would going to execute in parallel on three different CPUs. So needless to say, they will going to accomplish the total work much faster than as compared to the concurrent example that we discussed in the previous lecture video. In parallelization no threads ever block or take away the CPU from other threads in the system. All the threads can happily execute their processing on their respective CPUs in parallel.

now finally let us see that how multiple threads execute in a singular fashion on a typical computer system. So the problem statement remains the same, that there are three threads and each of these threads have their respective work to do. Now let us impose the constraints of singularism on the execution of these three threads, and we will notice that the operating system will allocate CPU to the thread T1 right. And it will not take away the CPU from the thread t1 until the thread t1 completes its work. Right. So it means that there is no context switching or there is no preemption of threads in the singular pattern of execution. Now let us suppose that the thread T1 has completed its task. Task here means the computation of summation of all the elements of the portion of the array assigned to the thread T1. Now, once the thread T1 has finished, the operating system will going to assign the another thread on the CPU. The thread T2 has waited until the thread T1 has completed its job and now the thread T3 is waiting until the thread T2 completes its job. So it means that in the singular pattern of thread execution there is no progression. The thread T3 has not even started its work and when the CPU is taken away from the thread T2, then the operating system will finally allocate the CPU to the thread t3. So this is how the threads will going to execute in the singular fashion. And in this example, it really don't matter whether you have one CPU or three CPUs. If you had three CPUs then the other two CPUs were going to go waste. They are not being used at all.

Either there exist concurrency or parallelism or both. But singular fashion of execution of threads doesn't really exist in the practical world. So with all this discussion in place, we can again conclude one more time that the time taken in parallelism is way less than the time taken in singularism fashion of execution of threads and the time taken in singular execution of threads is less than the time taken in concurrent execution of threads. I've already explained the reasoning behind this equation that in the concurrent fashion of execution of threads, a lot of time is wasted in only context switching between the threads. Always note that a context switching is an expensive operation to do. So now the question arises that a singular fashion of execution of the threads is not a practical approach of allocation of CPU to the threads. And what exists in the actual practical world is the parallel way of execution of threads and the concurrent way of execution of threads. Today's modern computer systems are actually hybrid system, which supports the parallel execution of threads together with concurrent execution of threads.
